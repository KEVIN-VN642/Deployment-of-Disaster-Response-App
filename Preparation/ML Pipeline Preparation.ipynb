{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pickle\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet'])\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///Disaster.db')\n",
    "df = pd.read_sql_table('data', engine)\n",
    "\n",
    "X = df.message\n",
    "y = df[df.columns[4:]]\n",
    "category_names = y.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['related', 'request', 'offer', 'aid_related', 'medical_help',\n",
       "       'medical_products', 'search_and_rescue', 'security', 'military',\n",
       "       'water', 'food', 'shelter', 'clothing', 'money', 'missing_people',\n",
       "       'refugees', 'death', 'other_aid', 'infrastructure_related', 'transport',\n",
       "       'buildings', 'electricity', 'tools', 'hospitals', 'shops',\n",
       "       'aid_centers', 'other_infrastructure', 'weather_related', 'floods',\n",
       "       'storm', 'fire', 'earthquake', 'cold', 'other_weather',\n",
       "       'direct_report'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    #remove non-alphanumeric characters\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(tokenizer=<function tokenize at 0x0000024409F6B8B0>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier()))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.29      0.41      1542\n",
      "           1       0.82      0.97      0.89      5012\n",
      "\n",
      "    accuracy                           0.81      6554\n",
      "   macro avg       0.78      0.63      0.65      6554\n",
      "weighted avg       0.80      0.81      0.77      6554\n",
      " \n",
      "*****************************************************\n",
      "request :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      5429\n",
      "           1       0.88      0.44      0.58      1125\n",
      "\n",
      "    accuracy                           0.89      6554\n",
      "   macro avg       0.89      0.71      0.76      6554\n",
      "weighted avg       0.89      0.89      0.88      6554\n",
      " \n",
      "*****************************************************\n",
      "offer :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6533\n",
      "           1       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           1.00      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      1.00      1.00      6554\n",
      " \n",
      "*****************************************************\n",
      "aid_related :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.82      3841\n",
      "           1       0.79      0.62      0.70      2713\n",
      "\n",
      "    accuracy                           0.78      6554\n",
      "   macro avg       0.78      0.75      0.76      6554\n",
      "weighted avg       0.78      0.78      0.77      6554\n",
      " \n",
      "*****************************************************\n",
      "medical_help :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      6051\n",
      "           1       0.60      0.06      0.11       503\n",
      "\n",
      "    accuracy                           0.92      6554\n",
      "   macro avg       0.77      0.53      0.53      6554\n",
      "weighted avg       0.90      0.92      0.90      6554\n",
      " \n",
      "*****************************************************\n",
      "medical_products :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6225\n",
      "           1       0.64      0.05      0.09       329\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.80      0.52      0.53      6554\n",
      "weighted avg       0.94      0.95      0.93      6554\n",
      " \n",
      "*****************************************************\n",
      "search_and_rescue :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      6364\n",
      "           1       0.82      0.05      0.09       190\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.90      0.52      0.54      6554\n",
      "weighted avg       0.97      0.97      0.96      6554\n",
      " \n",
      "*****************************************************\n",
      "security :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6426\n",
      "           1       0.33      0.01      0.02       128\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.66      0.50      0.50      6554\n",
      "weighted avg       0.97      0.98      0.97      6554\n",
      " \n",
      "*****************************************************\n",
      "military :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6343\n",
      "           1       0.83      0.05      0.09       211\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.90      0.52      0.54      6554\n",
      "weighted avg       0.96      0.97      0.96      6554\n",
      " \n",
      "*****************************************************\n",
      "water :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      6108\n",
      "           1       0.89      0.19      0.31       446\n",
      "\n",
      "    accuracy                           0.94      6554\n",
      "   macro avg       0.91      0.59      0.64      6554\n",
      "weighted avg       0.94      0.94      0.93      6554\n",
      " \n",
      "*****************************************************\n",
      "food :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      5820\n",
      "           1       0.88      0.38      0.53       734\n",
      "\n",
      "    accuracy                           0.92      6554\n",
      "   macro avg       0.90      0.69      0.75      6554\n",
      "weighted avg       0.92      0.92      0.91      6554\n",
      " \n",
      "*****************************************************\n",
      "shelter :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      5992\n",
      "           1       0.83      0.27      0.40       562\n",
      "\n",
      "    accuracy                           0.93      6554\n",
      "   macro avg       0.88      0.63      0.68      6554\n",
      "weighted avg       0.93      0.93      0.92      6554\n",
      " \n",
      "*****************************************************\n",
      "clothing :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6460\n",
      "           1       0.50      0.04      0.08        94\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.74      0.52      0.54      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      " \n",
      "*****************************************************\n",
      "money :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6395\n",
      "           1       0.80      0.03      0.05       159\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.89      0.51      0.52      6554\n",
      "weighted avg       0.97      0.98      0.97      6554\n",
      " \n",
      "*****************************************************\n",
      "missing_people :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6472\n",
      "           1       0.00      0.00      0.00        82\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      " \n",
      "*****************************************************\n",
      "refugees :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6327\n",
      "           1       0.75      0.03      0.05       227\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.86      0.51      0.52      6554\n",
      "weighted avg       0.96      0.97      0.95      6554\n",
      " \n",
      "*****************************************************\n",
      "death :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6278\n",
      "           1       0.79      0.11      0.19       276\n",
      "\n",
      "    accuracy                           0.96      6554\n",
      "   macro avg       0.88      0.55      0.59      6554\n",
      "weighted avg       0.95      0.96      0.95      6554\n",
      " \n",
      "*****************************************************\n",
      "other_aid :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      5659\n",
      "           1       0.75      0.02      0.03       895\n",
      "\n",
      "    accuracy                           0.86      6554\n",
      "   macro avg       0.81      0.51      0.48      6554\n",
      "weighted avg       0.85      0.86      0.81      6554\n",
      " \n",
      "*****************************************************\n",
      "infrastructure_related :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97      6118\n",
      "           1       0.00      0.00      0.00       436\n",
      "\n",
      "    accuracy                           0.93      6554\n",
      "   macro avg       0.47      0.50      0.48      6554\n",
      "weighted avg       0.87      0.93      0.90      6554\n",
      " \n",
      "*****************************************************\n",
      "transport :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6243\n",
      "           1       0.73      0.07      0.13       311\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.84      0.53      0.55      6554\n",
      "weighted avg       0.95      0.95      0.94      6554\n",
      " \n",
      "*****************************************************\n",
      "buildings :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6220\n",
      "           1       0.73      0.07      0.13       334\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.84      0.54      0.55      6554\n",
      "weighted avg       0.94      0.95      0.93      6554\n",
      " \n",
      "*****************************************************\n",
      "electricity :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6411\n",
      "           1       1.00      0.02      0.04       143\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.99      0.51      0.52      6554\n",
      "weighted avg       0.98      0.98      0.97      6554\n",
      " \n",
      "*****************************************************\n",
      "tools :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6519\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      0.99      0.99      6554\n",
      " \n",
      "*****************************************************\n",
      "hospitals :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6471\n",
      "           1       0.00      0.00      0.00        83\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.97      0.99      0.98      6554\n",
      " \n",
      "*****************************************************\n",
      "shops :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6526\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           1.00      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      1.00      0.99      6554\n",
      " \n",
      "*****************************************************\n",
      "aid_centers :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6484\n",
      "           1       0.00      0.00      0.00        70\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      " \n",
      "*****************************************************\n",
      "other_infrastructure :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      6255\n",
      "           1       0.50      0.00      0.01       299\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.73      0.50      0.49      6554\n",
      "weighted avg       0.93      0.95      0.93      6554\n",
      " \n",
      "*****************************************************\n",
      "weather_related :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.92      4742\n",
      "           1       0.86      0.64      0.73      1812\n",
      "\n",
      "    accuracy                           0.87      6554\n",
      "   macro avg       0.87      0.80      0.82      6554\n",
      "weighted avg       0.87      0.87      0.87      6554\n",
      " \n",
      "*****************************************************\n",
      "floods :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      5993\n",
      "           1       0.92      0.40      0.56       561\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.93      0.70      0.77      6554\n",
      "weighted avg       0.94      0.95      0.94      6554\n",
      " \n",
      "*****************************************************\n",
      "storm :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      5946\n",
      "           1       0.78      0.45      0.57       608\n",
      "\n",
      "    accuracy                           0.94      6554\n",
      "   macro avg       0.86      0.72      0.77      6554\n",
      "weighted avg       0.93      0.94      0.93      6554\n",
      " \n",
      "*****************************************************\n",
      "fire :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6480\n",
      "           1       0.00      0.00      0.00        74\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      " \n",
      "*****************************************************\n",
      "earthquake :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      5974\n",
      "           1       0.88      0.77      0.82       580\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.93      0.88      0.90      6554\n",
      "weighted avg       0.97      0.97      0.97      6554\n",
      " \n",
      "*****************************************************\n",
      "cold :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6438\n",
      "           1       0.54      0.06      0.11       116\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.76      0.53      0.55      6554\n",
      "weighted avg       0.98      0.98      0.98      6554\n",
      " \n",
      "*****************************************************\n",
      "other_weather :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6202\n",
      "           1       0.45      0.03      0.05       352\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.70      0.51      0.51      6554\n",
      "weighted avg       0.92      0.95      0.92      6554\n",
      " \n",
      "*****************************************************\n",
      "direct_report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92      5283\n",
      "           1       0.86      0.35      0.50      1271\n",
      "\n",
      "    accuracy                           0.86      6554\n",
      "   macro avg       0.86      0.67      0.71      6554\n",
      "weighted avg       0.86      0.86      0.84      6554\n",
      " \n",
      "*****************************************************\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "#print f1 score, precision and recall for each output category\n",
    "for i in range(y_pred.shape[1]):\n",
    "    print(y_test.columns[i], ':')\n",
    "    print(classification_report(y_test.iloc[:,i], y_pred[:,i], zero_division = 0), \"\\n*****************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Average precision, recall and f1-score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision for 0 class:  0.943547643707954\n",
      "Average recall for 0 class:  0.9729544666256901\n",
      "Average F1-score for 0 class:  0.9545614774748651\n",
      "Average precision for 1 class:  0.5762021272845644\n",
      "Average recall for 1 class:  0.17611184912262487\n",
      "Average F1-score for 1 class:  0.22471225103230627\n"
     ]
    }
   ],
   "source": [
    "zero_precision = []\n",
    "zero_recall = []\n",
    "zero_f1 = []\n",
    "\n",
    "one_precision = []\n",
    "one_recall = []\n",
    "one_f1 = []\n",
    "\n",
    "for i in range(y_pred.shape[1]):\n",
    "    cf_matrix = classification_report(y_test.iloc[:,i], y_pred[:,i], output_dict = True, zero_division = 0)\n",
    "    \n",
    "    zero_precision.append(cf_matrix['0']['precision'])\n",
    "    zero_recall.append(cf_matrix['0']['recall'])\n",
    "    zero_f1.append(cf_matrix['0']['f1-score'])\n",
    "    \n",
    "    one_precision.append(cf_matrix['1']['precision'])\n",
    "    one_recall.append(cf_matrix['1']['recall'])\n",
    "    one_f1.append(cf_matrix['1']['f1-score'])\n",
    "\n",
    "print('Average precision for 0 class: ', np.mean(zero_precision))    \n",
    "print('Average recall for 0 class: ', np.mean(zero_recall))  \n",
    "print('Average F1-score for 0 class: ', np.mean(zero_f1))    \n",
    "\n",
    "print('Average precision for 1 class: ', np.mean(one_precision))    \n",
    "print('Average recall for 1 class: ', np.mean(one_recall))  \n",
    "print('Average F1-score for 1 class: ', np.mean(one_f1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MLclassifier.pkl', 'wb') as file:\n",
    "    pickle.dump(pipeline, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
